<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Profiling your compiled code on A Tour of PyTorch 2.0</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/5_profiling-torch_compile/</link><description>Recent content in Profiling your compiled code on A Tour of PyTorch 2.0</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 29 Mar 2023 15:47:39 -0700</lastBuildDate><atom:link href="http://shashankprasanna.com/workshops/a-tour-of-pytorch2/5_profiling-torch_compile/index.xml" rel="self" type="application/rss+xml"/><item><title>Profiling torch.compile()</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/5_profiling-torch_compile/profiling_torch_compile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/5_profiling-torch_compile/profiling_torch_compile/</guid><description>For this example, we&amp;rsquo;ll define yet another simple function. We&amp;rsquo;ll use the taylor series expansion of sin(x). We choose this in particular for 2 reasons.
To show torch.compile can generate C++/CUDA code for a variety of functions not just neural network models You can grow this function to be arbtrarily large by simply adding more terms to the series expansion import torch import math import os import matplotlib.pyplot as plt from torch import optim import torch.</description></item></channel></rss>