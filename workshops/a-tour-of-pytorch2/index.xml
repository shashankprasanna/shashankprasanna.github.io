<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>A Tour of PyTorch 2.0</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/</link><description>Recent content on A Tour of PyTorch 2.0</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 29 Mar 2023 15:47:39 -0700</lastBuildDate><atom:link href="http://shashankprasanna.com/workshops/a-tour-of-pytorch2/index.xml" rel="self" type="application/rss+xml"/><item><title>A simple example</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/3_getting_started/a_simple_example/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/3_getting_started/a_simple_example/</guid><description>How to use torch.compile() : A simple example Load necessary modules, we&amp;rsquo;ll discuss the strange torch._dynamo bit a little later.
import torch import torch.nn as nn from torchvision.models import resnet import torch._dynamo device = torch.device(&amp;#34;cuda&amp;#34;) if torch.cuda.is_available() else &amp;#34;cpu&amp;#34; Define a very simple NN and compile it with torch.compile() and compare the results with your model to convince yourself that it won&amp;rsquo;t break your code.
class MLP(nn.Module): def __init__(self): super().__init__() self.</description></item><item><title>Inspecting torch.compile()</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/4_inspecting_torch_compile/inspecting_torch_compile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/4_inspecting_torch_compile/inspecting_torch_compile/</guid><description>In this section we&amp;rsquo;ll define a very simple function and analyze what&amp;rsquo;s happening under the hood.
import torch import math import os import matplotlib.pyplot as plt from torch import optim import torch._dynamo from torchvision import models from torch.profiler import profile, record_function, ProfilerActivity pi = math.pi device = torch.device(&amp;#34;cuda&amp;#34;) if torch.cuda.is_available() else &amp;#34;cpu&amp;#34; Define a simple function sin^2(x) + cos^2(x), as you know this equals 1 for all real values of x</description></item><item><title>Profiling torch.compile()</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/5_profiling-torch_compile/profiling_torch_compile/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/5_profiling-torch_compile/profiling_torch_compile/</guid><description>For this example, we&amp;rsquo;ll define yet another simple function. We&amp;rsquo;ll use the taylor series expansion of sin(x). We choose this in particular for 2 reasons.
To show torch.compile can generate C++/CUDA code for a variety of functions not just neural network models You can grow this function to be arbtrarily large by simply adding more terms to the series expansion import torch import math import os import matplotlib.pyplot as plt from torch import optim import torch.</description></item><item><title>Benchmarking Resnet</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/3_getting_started/benchmarking_resnet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/3_getting_started/benchmarking_resnet/</guid><description>Benchmark a Resnet18 model Now we&amp;rsquo;ll add some additional code to benchmark the training and inference workflows with random data. We&amp;rsquo;ll use the default settings with torch.compile() and then introduce different modes of operation: torch.compile(...,mode='reduce-overhead') and torch.compile(...,mode='max-autotune')
Performance depends on various factors such as your model type, system configuration and GPU type You may not always see a speedup. In the subsequent sections we&amp;rsquo;ll see how to profile and identify potential issues.</description></item><item><title>Benchmarking Huggingface</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/3_getting_started/hugging_face/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/3_getting_started/hugging_face/</guid><description>Let&amp;rsquo;s try a language mode with HuggingFace
import torch from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC from datasets import load_dataset torch.set_float32_matmul_precision(&amp;#39;high&amp;#39;) def run_hf_inference(model, input_values): # retrieve logits logits = model(input_values).logits # take argmax and decode predicted_ids = torch.argmax(logits, dim=-1) transcription = processor.batch_decode(predicted_ids) # load model and processor processor = Wav2Vec2Processor.from_pretrained(&amp;#34;facebook/wav2vec2-large-960h-lv60-self&amp;#34;) model = Wav2Vec2ForCTC.from_pretrained(&amp;#34;facebook/wav2vec2-large-960h-lv60-self&amp;#34;).cuda() # load dummy dataset and read soundfiles ds = load_dataset(&amp;#34;patrickvonplaten/librispeech_asr_dummy&amp;#34;, &amp;#34;clean&amp;#34;, split=&amp;#34;validation&amp;#34;) # tokenize input_values = processor(ds[0][&amp;#34;audio&amp;#34;][&amp;#34;array&amp;#34;], return_tensors=&amp;#34;pt&amp;#34;, padding=&amp;#34;longest&amp;#34;).input_values.cuda() batch = 1 torch.</description></item><item><title>Free CPU and GPU options</title><link>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/1_workshop_setup/free_options/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://shashankprasanna.com/workshops/a-tour-of-pytorch2/1_workshop_setup/free_options/</guid><description>Install locally If you have a CPU-only or a CPU+GPU laptop or workstation you can install PyTorch 2.0 locally by following these instructions:
https://pytorch.org/get-started/locally/
Google Colab Google colab is a free cloud hosted Jupyter based environment. You can get access to GPUs and TPUs to run PyTorch 2.0. Log into Google colab with your google account and open up a new Jupyter Notebook.
!pip3 install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.</description></item></channel></rss>