<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.118.2"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Why I joined Modular AI? | Shashank Prasanna</title><meta name=description content="Towards a better development tools for AI"><meta property="og:title" content="Why I joined Modular AI?"><meta property="og:description" content="Towards a better development tools for AI"><meta property="og:type" content="article"><meta property="og:url" content="https://shashankprasanna.com/why-i-joined-modular-ai/"><meta property="og:image" content="https://shashankprasanna.com/why-i-joined-modular-ai/featured-background.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2023-06-23T00:00:00+00:00"><meta property="article:modified_time" content="2023-06-23T00:00:00+00:00"><meta itemprop=name content="Why I joined Modular AI?"><meta itemprop=description content="Towards a better development tools for AI"><meta itemprop=datePublished content="2023-06-23T00:00:00+00:00"><meta itemprop=dateModified content="2023-06-23T00:00:00+00:00"><meta itemprop=wordCount content="905"><meta itemprop=image content="https://shashankprasanna.com/why-i-joined-modular-ai/featured-background.png"><meta itemprop=keywords content="Modular,mojo,AI,career,"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shashankprasanna.com/why-i-joined-modular-ai/featured-background.png"><meta name=twitter:title content="Why I joined Modular AI?"><meta name=twitter:description content="Towards a better development tools for AI"><link rel=preload href=/scss/main.min.69537fa29b588a0489895f73e23bb15ef971d18488cb8464157b4024198e733a.css as=style><link href=/scss/main.min.69537fa29b588a0489895f73e23bb15ef971d18488cb8464157b4024198e733a.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-20Q10LSLZ7"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-20Q10LSLZ7")}</script></head><body class="td-page td-blog"><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>Shashank Prasanna</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/><span class=active>Home</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://medium.com/@shashankprasanna target=_blank><i class='fa-brands fa-medium'></i><span>Medium+TDS</span><sup><i class='ps-1 fa-solid fa-up-right-from-square fa-xs' aria-hidden=true></i></sup></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/blog/><span class=active>Blog</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.8dec93ffbb0c56474b088af8fbb8214c.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.8dec93ffbb0c56474b088af8fbb8214c.json data-offline-search-base-href=/ data-offline-search-max-results=10></div><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-blog-li><a href=/blog/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-blog><span>Blog</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-why-i-joined-modular-ai-li><a href=/why-i-joined-modular-ai/ class="align-left pl-0 active td-sidebar-link td-sidebar-link__page" id=m-why-i-joined-modular-ai><span class=td-sidebar-nav-active-item>Why I joined Modular AI?</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-benchmarking-modular-mojo-and-pytorch-torchcompile-on-mandelbrot-function-li><a href=/benchmarking-modular-mojo-and-pytorch-torch.compile-on-mandelbrot-function/ title="Benchmarking Modular Mojo🔥 and PyTorch torch.compile() on Mandelbrot function" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-benchmarking-modular-mojo-and-pytorch-torchcompile-on-mandelbrot-function><span>Benchmarking Modular Mojo and PyTorch torch.compile() on Mandelbrot function</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-how-pytorch-20-accelerates-deep-learning-with-operator-fusion-and-cpugpu-code-generation-li><a href=/how-pytorch-2.0-accelerates-deep-learning-with-operator-fusion-and-cpu/gpu-code-generation/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-how-pytorch-20-accelerates-deep-learning-with-operator-fusion-and-cpugpu-code-generation><span>How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution-li><a href=/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution><span>AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators-li><a href=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators><span>How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-automatically-generate-code-and-documentation-using-openai-codex-li><a href=/automatically-generate-code-and-documentation-using-openai-codex/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-automatically-generate-code-and-documentation-using-openai-codex><span>Automatically generate code and documentation using OpenAI CODEX</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference-li><a href=/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference><span>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-choosing-the-right-gpu-for-deep-learning-on-aws-li><a href=/choosing-the-right-gpu-for-deep-learning-on-aws/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-choosing-the-right-gpu-for-deep-learning-on-aws><span>Choosing the right GPU for deep learning on AWS</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><div class=box><img style=vertical-align:middle src=https://shashankprasanna.com/featured-background.png alt="shashank prasanna" width=200></div><a href=https://github.com/shashankprasanna/shashankprasanna.com/tree/main/content/en/blog/why-i-joined-modular-ai/index.md class=td-page-meta--view target=_blank rel=noopener><i class="fa fa-file-alt fa-fw"></i> View page source</a>
<a href=https://github.com/shashankprasanna/shashankprasanna.com/edit/main/content/en/blog/why-i-joined-modular-ai/index.md class=td-page-meta--edit target=_blank rel=noopener><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="https://github.com/shashankprasanna/shashankprasanna.com/new/main/content/en/blog/why-i-joined-modular-ai/index.md?filename=change-me.md&amp;value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" class=td-page-meta--child target=_blank rel=noopener><i class="fa fa-edit fa-fw"></i> Create child page</a>
<a href="https://github.com/shashankprasanna/shashankprasanna.com/issues/new?title=Why%20I%20joined%20Modular%20AI?" class=td-page-meta--issue target=_blank rel=noopener><i class="fas fa-tasks fa-fw"></i> Create documentation issue</a>
<a href=https://github.com/shashankprasanna/shashankprasanna.com/issues/new class=td-page-meta--project-issue target=_blank rel=noopener><i class="fas fa-tasks fa-fw"></i> Create project issue</a></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#enter-modular-ai>Enter Modular AI</a></li></ul></nav></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role=main><font color=black size=5></font>
<a class=td-rss-button title=RSS href=https://shashankprasanna.com/blog/index.xml target=_blank rel=noopener><i class="fa-solid fa-rss" aria-hidden=true></i></a><div class=td-content><h1>Why I joined Modular AI?</h1><div class=lead>Towards a better development tools for AI</div><div class="td-byline mb-4">By <b>Shashank Prasanna</b> |
<time datetime=2023-06-23 class=text-muted>Friday, June 23, 2023</time></div><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/modular/ data-taxonomy-term=modular><span class=taxonomy-label>modular</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/mojo/ data-taxonomy-term=mojo><span class=taxonomy-label>mojo</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/ai/ data-taxonomy-term=ai><span class=taxonomy-label>AI</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/career/ data-taxonomy-term=career><span class=taxonomy-label>career</span></a></li></ul></div></header><p><img src=featured-background.png alt>
In the past decade, I&rsquo;ve had the very good fortune of working for companies that make some of the best and proven developer productivity tools. If you&rsquo;re an engineer who&rsquo;s built control systems for rockets, cars or robots you&rsquo;ve used MATLAB and Simulink. If you&rsquo;re an AI developer you likely have an NVIDIA GPU at arm&rsquo;s reach (ssh to AWS EC2 counts as arm&rsquo;s reach). If you&rsquo;re a developer running software in production you&rsquo;ve likely relied on AWS services for their scalability and and reliability for deployment. If you&rsquo;re an AI researcher there is no better tool than PyTorch to go from research paper to trained model.</p><p>What these tools have in common is that they are individually, in my personal opinion, UNPARALLELED at what they do. However, when you start stringing multiple of these tools together, then their productivity promise breaks down. You already know this if you&rsquo;re training custom models using some or all of these tools. I&rsquo;ve spend the last several years talking about the the role of AI software and specialized AI hardware and the challenges with using multiple frameworks and AI accelerators during development and deployment and you can read about them <a href=https://shashankprasanna.com/popular_blog_posts/>in my blog posts.</a></p><p>If you start AI development today, you&rsquo;ll need answers to these questions before you start your project since it has huge implication on what tools you will use:</p><div class="td-card card mb-4"><div class=card-header><h5 id=during-prototyping-and-development>During prototyping and development</h5></div><div class=card-body><p class=card-text><ol><li>Should you decide on the framework ahead of time (PyTorch, TensorFlow,?)</li><li>Should you decide where you&rsquo;re going to run it later (GPU, TPU, Intel Habana, AWS Silicon etc.)?</li><li>Should you write 5 versions of custom layer Op for each potential AI accelerators you want to target?</li><li>Will your code run as-is when you go from laptop to cloud? on x86 and ARM CPUs? what about GPUs? What about other AI accelerators (AWS Silicon, Intel Habana Gaudi)?</li><li>Will your code scale out of the box? will it scale on non-GPU AI accelerators? Will it work on all network hardware? between accelerators? between nodes?</li><li>If you want to write non-ML code (e.g. data processing, control algorithm etc.) will that accelerate on CPUs, GPUs, AI Accelerators? What language do you write it in?</li></ol></p></div></div><div class="td-card card mb-4"><div class=card-header><h5 id=during-production-deployment>During production deployment</h5></div><div class=card-body><p class=card-text><ol><li>What serving framework will you use, was it designed for production or for AI research and prototyping</li><li>Will it support multiple framework model formats?</li><li>Does it run on x86, ARM, AI accelerators for inference?</li><li>Can it run on embedded devices, what architectures are supported?</li><li>Can it do model parallel on different AI accelerators?</li><li>Can you meet your target throughput for desired latency at lower cost?</li><li>Can you monitor performance and accuracy metrics?</li></ol></p></div></div><p><strong>It&rsquo;s exhausting isn&rsquo;t it?</strong></p><p>The disadvantage of using disparate systems is that you risk months or years of reworking, re-tooling and re-implementing when something very small changes, such as - deciding to run on different hardware: GPUs and another AI accelerators, or implement custom models for multiple different frameworks or languages.</p><p>Unfortunately, there aren&rsquo;t a great solutions for these challenges today. What we need a very small, tight set of tools, that is performant, reliable that works well together, runs everywhere and is modular. You see where I&rsquo;m going with this.</p><h2 id=enter-modular-ai>Enter Modular AI</h2><p>And that brings me to why I decided to join Modular. I share Modular co-founders Chris Lattner (LLVM, Swift) and Tim Davis&rsquo;s vision that AI tools are <strong>broken today and can be better</strong> and when fixed, can infinitely improve developer productivity. <strong>AI tools can be more usable. AI tools can be more accessible. AI tools can make developers more productive which will make AI itself more accessible to everyone in the world.</strong> There will be a future when you don&rsquo;t have to have answers to the questions ahead of time. You start your work, introduce different hardware, introduce custom models and extensions and stuff will just work. On any system. Deployed anywhere. And you only use one language. And deploy with one runtime engine.</p><p>If I&rsquo;ve piqued your interest, come check out the products we&rsquo;re building at <a href=https://www.modular.com/>Modular AI</a>:</p><ul><li><strong>Mojo🔥</strong> programming language that combines the usability of Python with the performance of C. You can write your custom kernels and ops in Mojo, so your entire stack that&rsquo;ll run on multiple AI accelerators is in one language which is a superset of Python!</li><li><strong>Modular Engine</strong> is an AI inference engine built with Mojo🔥 that gives you unparalleled performance and runs PyTorch and TensorFlow models on multiple hardware.</li></ul><p>Good tools make us productive, they bring us joy, the same joy you get when you find the right screw driver for that pesky loose screw, the right sized wrench, the right drill - no other makeshift tool will bring you that satisfaction of the right tool for the job. Practitioners in every domain need tools to build, create, solve, and implement more efficiently and AI is no different. <strong>We need better AI tools for developers and I believe Modular will play a significant role in building them.</strong></p><p>We&rsquo;re in early days, and Mojo and Modular Engine are not generally available yet, but you can try Mojo in the Mojo playground and see the performance speedups for yourself. <a href=https://www.modular.com/get-started>Signup here to get access</a> to Mojo playground and learn more about other Modular products. Follow me on Twitter <a href=https://twitter.com/shshnkp>@shshnkp</a>, read my blog posts on Medium (and here) <a href=https://medium.com/@shashankprasanna>@shashank.prasanna</a> and connect with me on <a href=https://www.linkedin.com/in/shashankprasanna/>LinkedIn</a> as I&rsquo;ll be sharing a Modular&rsquo;s journey and educational content. Thanks for reading!</p><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/benchmarking-modular-mojo-and-pytorch-torch.compile-on-mandelbrot-function/ aria-label="Previous - Benchmarking Modular Mojo🔥 and PyTorch torch.compile() on Mandelbrot function" class="btn btn-primary"><span class=mr-1>←</span>Previous</a></li><li><a class="btn btn-primary disabled">Next<span class=ml-1>→</span></a></li></ul></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://twitter.com/shshnkp aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=LinkedIn aria-label=LinkedIn><a class=text-white target=_blank rel=noopener href=https://www.linkedin.com/in/shashankprasanna/ aria-label=LinkedIn><i class="fab fa-linkedin"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/shashankprasanna/ aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=YouTube aria-label=YouTube><a class=text-white target=_blank rel=noopener href=https://www.youtube.com/@shashank.prasanna aria-label=YouTube><i class="fab fa-youtube"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Medium aria-label=Medium><a class=text-white target=_blank rel=noopener href=https://medium.com/@shashankprasanna aria-label=Medium><i class="fab fa-medium"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2023 Shashank Prasanna All Rights Reserved</small></div></div></div></footer></div><script src=/js/main.min.2aff983e9d0d8ecff9ed53e14b657216e2d8d2aff059bf4a5651283020995f1b.js integrity="sha256-Kv+YPp0Njs/57VPhS2VyFuLY0q/wWb9KVlEoMCCZXxs=" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script></body></html>