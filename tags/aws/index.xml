<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aws on Shashank Prasanna</title><link>/tags/aws/</link><description>Recent content in Aws on Shashank Prasanna</description><generator>Hugo</generator><language>en</language><lastBuildDate>Wed, 24 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/aws/index.xml" rel="self" type="application/rss+xml"/><item><title>How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</title><link>/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/</link><pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate><guid>/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/</guid><description>&lt;p>If you told me a few years ago that data scientists would be using Docker containers in their day to day work, I wouldn’t have believed you. As a member of the broader machine learning (ML) community I always considered Docker, Kubernetes, Swarm (remember that?) exotic infrastructure tools for IT/Ops experts. Today it’s a different story, rarely a day goes by when I don’t use a Docker container for training or hosting a model.
An attribute of machine learning development that makes it different from traditional software development is that it relies on specialized hardware such as GPUs, Habana Gaudi, AWS Inferentia to accelerate training and inference. This makes it challenging to have containerized deployments that are hardware-agnostic, which is one of the key benefits of containers. In this blog post I’ll discuss how Docker and container technologies have evolved to address this challenge. We’ll discuss:&lt;/p></description></item><item><title>Best GPUs on AWS for Deep Learning</title><link>/best-gpus-on-aws-for-deep-learning/</link><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid>/best-gpus-on-aws-for-deep-learning/</guid><description>&lt;p>Here are 5 GPU instance recommendations on AWS that should serve majority of deep learning use-cases. For a complete deep dive into choosing the right GPU for deep learning on AWS, read my blog post:&lt;/p>


&lt;div class="alert alert-primary" role="alert">


 &lt;h3 id="choosing-the-right-gpu-for-deep-learning-on-aws">&lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">Choosing the right GPU for deep learning on AWS&lt;/a>&lt;/h3>


&lt;/div>

&lt;div class="td-card card border me-4">
&lt;div class="card-header">
 &lt;strong>Highest performing multi-GPU instance on AWS&lt;/strong>
 &lt;/div>
&lt;div class="card-body">
 &lt;p class="card-text">
&lt;p>&lt;img src="/best-gpus-on-aws-for-deep-learning/gpu1.png" alt="GPU">&lt;/p>
&lt;p>&lt;strong>Instance: p4d.24xlarge&lt;/strong>&lt;/p>
&lt;p>&lt;strong>When to use it:&lt;/strong> When you need all the performance you can get. Use it for distributed training on large models and datasets.&lt;/p></description></item><item><title>Choosing the right GPU for deep learning on AWS</title><link>/choosing-the-right-gpu-for-deep-learning-on-aws/</link><pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate><guid>/choosing-the-right-gpu-for-deep-learning-on-aws/</guid><description>&lt;p>On AWS, you can launch GPU instances with different GPU memory sizes (8 GB, 16 GB, 24 GB, 32 GB, 40 GB), NVIDIA GPU generations (Ampere, Turing, Volta, Maxwell, Kepler) different capabilities (FP64, FP32, FP16, INT8, Sparsity, TensorCores, NVLink), different number of GPUs per instance (1, 2, 4, 8, 16), and paired with different CPUs (Intel, AMD, Graviton2). You can also select instances with different vCPUs (core thread count), system memory and network bandwidth and add a range of storage options (object storage, network file systems, block storage, etc.) — in summary, you have options.&lt;/p></description></item></channel></rss>