<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Shashank Prasanna – aws</title><link>/tags/aws/</link><description>Recent content in aws on Shashank Prasanna</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 24 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/aws/index.xml" rel="self" type="application/rss+xml"/><item><title>Blog: How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</title><link>/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/</link><pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate><guid>/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/</guid><description>
&lt;img src="/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/featured_hu40258b408388e57d94159bf91c739a7c_102531_640x0_resize_catmullrom_3.png" width="640" height="285"/>
&lt;p>If you told me a few years ago that data scientists would be using Docker containers in their day to day work, I wouldn’t have believed you. As a member of the broader machine learning (ML) community I always considered Docker, Kubernetes, Swarm (remember that?) exotic infrastructure tools for IT/Ops experts. Today it’s a different story, rarely a day goes by when I don’t use a Docker container for training or hosting a model.
An attribute of machine learning development that makes it different from traditional software development is that it relies on specialized hardware such as GPUs, Habana Gaudi, AWS Inferentia to accelerate training and inference. This makes it challenging to have containerized deployments that are hardware-agnostic, which is one of the key benefits of containers. In this blog post I’ll discuss how Docker and container technologies have evolved to address this challenge. We’ll discuss:&lt;/p>
&lt;ul>
&lt;li>Why Docker has become an essential tool for machine learning today and how it addresses machine learning specific challenges&lt;/li>
&lt;li>How Docker accesses specialized hardware resources on heterogeneous systems that have more than one type of processor (CPU + AI accelerators).&lt;/li>
&lt;li>How different AI accelerators extend Docker for hardware access with examples of 1/ NVIDIA GPUs and NVIDIA Container Toolkit and 2/ AWS Inferentia and Neuron SDK support for containers&lt;/li>
&lt;li>How to scale Docker containers on Kubernetes with hardware accelerated nodes&lt;/li>
&lt;/ul>
&lt;div class="td-card card border me-4">
&lt;div class="card-body">
&lt;h5 class="card-title">
Read the full blog post here:&lt;br>&lt;br> &lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/ai-accelerators-machine-learning-algorithms-and-their-co-design-and-evolution-2676efd47179">How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators&lt;/a>&lt;/h5>
&lt;p class="card-text">
&lt;/p>
&lt;/div>
&lt;div class="card-footer">
&lt;img src="featured.png" alt="">&lt;/div>
&lt;/div></description></item><item><title>Blog: Best GPUs on AWS for Deep Learning</title><link>/best-gpus-on-aws-for-deep-learning/</link><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid>/best-gpus-on-aws-for-deep-learning/</guid><description>
&lt;img src="/best-gpus-on-aws-for-deep-learning/gpu4-featured_hu93531d3f19a1a68a0fc2d3bfd6de5052_4220_640x0_resize_catmullrom_3.png" width="640" height="142"/>
&lt;p>Here are 5 GPU instance recommendations on AWS that should serve majority of deep learning use-cases. For a complete deep dive into choosing the right GPU for deep learning on AWS, read my blog post:&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;h3 id="i-classfa-brands-fa-mediumi-choosing-the-right-gpu-for-deep-learning-on-awshttpsmediumcomtowards-data-sciencechoosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">&lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">Choosing the right GPU for deep learning on AWS&lt;/a>&lt;/h3>
&lt;/div>
&lt;div class="td-card card border me-4">
&lt;div class="card-header">
&lt;strong>Highest performing multi-GPU instance on AWS&lt;/strong>
&lt;/div>
&lt;div class="card-body">
&lt;p class="card-text">
&lt;p>&lt;img src="gpu1.png" alt="GPU">&lt;/p>
&lt;p>&lt;strong>Instance: p4d.24xlarge&lt;/strong>&lt;/p>
&lt;p>&lt;strong>When to use it:&lt;/strong> When you need all the performance you can get. Use it for distributed training on large models and datasets.&lt;/p>
&lt;p>&lt;strong>What you get:&lt;/strong> 8 x NVIDIA A100 GPUs with 40 GB GPU memory per GPU. Based on the latest NVIDIA Ampere architecture. Includes 3rd generation NVLink for fast multi-GPU training.&lt;/p>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;br/>
&lt;div class="td-card card border me-4">
&lt;div class="card-header">
&lt;strong>Highest performing single-GPU instance on AWS&lt;/strong>
&lt;/div>
&lt;div class="card-body">
&lt;p class="card-text">
&lt;p>&lt;img src="gpu2.png" alt="GPU">&lt;/p>
&lt;p>&lt;strong>Instance: p3.2xlarge&lt;/strong>&lt;/p>
&lt;p>&lt;strong>When to use it:&lt;/strong> When you want the highest performance Single GPU and you’re fine with 16 GB of GPU memory.&lt;/p>
&lt;p>&lt;strong>What you get:&lt;/strong> 1 x NVIDIA V100 GPU with 16 GB of GPU memory. Based on the older NVIDIA Volta architecture. The best performing single-GPU is still the NVIDIA A100 on P4 instance, but you can only get 8 x NVIDIA A100 GPUs on P4. This GPU has a slight performance edge over NVIDIA A10G on G5 instance discussed next, but G5 is far more cost-effective and has more GPU memory.&lt;/p>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;br/>
&lt;div class="td-card card border me-4">
&lt;div class="card-header">
&lt;strong>Best performance/cost, single-GPU instance on AWS&lt;/strong>
&lt;/div>
&lt;div class="card-body">
&lt;p class="card-text">
&lt;p>&lt;img src="gpu3.png" alt="GPU">&lt;/p>
&lt;p>&lt;strong>Instance: g5.xlarge&lt;/strong>&lt;/p>
&lt;p>&lt;strong>When to use it:&lt;/strong> When you want high-performance, more GPU memory at lower cost than P3 instance&lt;/p>
&lt;p>&lt;strong>What you get:&lt;/strong> 1 x NVIDIA A10G GPU with 24 GB of GPU memory, based on the latest Ampere architecture. NVIDIA A10G can be seen as a lower powered cousin of the A100 on the p4d.24xlarge so it’s easy to migrate and scale when you need more compute. Consider larger sizes withg5.(2/4/8/16)xlarge for the same single-GPU with more vCPUs and higher system memory if you have more pre or post processing steps.&lt;/p>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;br/>
&lt;div class="td-card card border me-4">
&lt;div class="card-header">
&lt;strong>Best performance/cost, multi-GPU instance on AWS&lt;/strong>
&lt;/div>
&lt;div class="card-body">
&lt;p class="card-text">
&lt;p>&lt;img src="gpu4-featured.png" alt="GPU">&lt;/p>
&lt;p>&lt;strong>Instance: p3.(8/16)xlarge&lt;/strong>&lt;/p>
&lt;p>&lt;strong>When to use it:&lt;/strong> Cost-effective multi-GPU model development and training.&lt;/p>
&lt;p>&lt;strong>What you get:&lt;/strong> p3.8xlarge has 4 x NVIDIA V100 GPUs and p3.16xlarge has 8 x NVIDIA V100 GPUs with 16 GB of GPU memory on each GPU, based on the older NVIDIA Volta architecture. For larger models, datasets and faster performance consider P4 instances.&lt;/p>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;br/>
&lt;div class="td-card card border me-4">
&lt;div class="card-header">
&lt;strong>High-performance GPU instance at a budget on AWS&lt;/strong>
&lt;/div>
&lt;div class="card-body">
&lt;p class="card-text">
&lt;p>&lt;img src="gpu5.png" alt="GPU">&lt;/p>
&lt;p>&lt;strong>Instance: g4dn.xlarge&lt;/strong>&lt;/p>
&lt;p>&lt;strong>When to use it:&lt;/strong> Lower performance than other options at lower cost for model development and training. Cost effective model inference deployment.&lt;/p>
&lt;p>&lt;strong>What you get:&lt;/strong> 1 x NVIDIA T4 GPU with 16 GB of GPU memory. Based on the previous generation NVIDIA Turing architecture. Consider g4dn.(2/4/8/16)xlarge for more vCPUs and higher system memory if you have more pre or post processing.&lt;/p>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;br/>
## Related blog posts
&lt;div class="td-card-group card-group p-0 mb-4">
&lt;div class="td-card card border me-4">
&lt;div class="card-body">
&lt;h5 class="card-title">
&lt;img src="https://miro.medium.com/v2/resize:fit:4800/format:webp/1*SAgQSIEprO1looCxAdf52w.png" alt="">&lt;/h5>
&lt;/div>
&lt;div class="card-footer">
&lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/ai-accelerators-machine-learning-algorithms-and-their-co-design-and-evolution-2676efd47179">AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution&lt;/a>&lt;/div>
&lt;/div>
&lt;div class="td-card card border me-4">
&lt;div class="card-body">
&lt;h5 class="card-title">
&lt;img src="https://miro.medium.com/v2/resize:fit:4800/format:webp/1*qAx5CnFbebRR_bOyQbSGYw.png" alt="">&lt;/h5>
&lt;/div>
&lt;div class="card-footer">
&lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">Choosing the right GPU for deep learning on AWS&lt;/a>&lt;/div>
&lt;/div>
&lt;div class="td-card card border me-4">
&lt;div class="card-body">
&lt;h5 class="card-title">
&lt;img src="https://miro.medium.com/v2/resize:fit:4800/0*Po5qTIX3N1ZJoJHd" alt="">&lt;/h5>
&lt;/div>
&lt;div class="card-footer">
&lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators-e076c6eb7802">How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators&lt;/a>&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Blog: Choosing the right GPU for deep learning on AWS</title><link>/choosing-the-right-gpu-for-deep-learning-on-aws/</link><pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate><guid>/choosing-the-right-gpu-for-deep-learning-on-aws/</guid><description>
&lt;img src="/choosing-the-right-gpu-for-deep-learning-on-aws/featured_hu3cf755c2b3f91847dc184a8c7feac088_100672_640x0_resize_catmullrom_3.png" width="640" height="453"/>
&lt;p>On AWS, you can launch GPU instances with different GPU memory sizes (8 GB, 16 GB, 24 GB, 32 GB, 40 GB), NVIDIA GPU generations (Ampere, Turing, Volta, Maxwell, Kepler) different capabilities (FP64, FP32, FP16, INT8, Sparsity, TensorCores, NVLink), different number of GPUs per instance (1, 2, 4, 8, 16), and paired with different CPUs (Intel, AMD, Graviton2). You can also select instances with different vCPUs (core thread count), system memory and network bandwidth and add a range of storage options (object storage, network file systems, block storage, etc.) — in summary, you have options.&lt;/p>
&lt;p>My goal with this blog post is to provide you with guidance on how you can choose the right GPU instance on AWS for your deep learning projects. I’ll discuss key features and benefits of various EC2 GPU instances, and workloads that are best suited for each instance type and size. If you’re new to AWS, or new to GPUs, or new to deep learning, my hope is that you’ll find the information you need to make the right choice for your projects.&lt;/p>
&lt;h4 id="topics-covered-in-this-blog-post">Topics covered in this blog post:&lt;/h4>
&lt;ol>
&lt;li>Key recommendations for the busy data scientist/ML practitioner&lt;/li>
&lt;li>Why you should choose the right GPU instance not just the right GPU&lt;/li>
&lt;li>Deep dive on GPU instance types: P4, P3, G5 (G5g), G4, P2 and G3&lt;/li>
&lt;li>Other machine learning accelerators and instances on AWS&lt;/li>
&lt;li>Cost optimization tips when using GPU instances for ML&lt;/li>
&lt;li>What software and frameworks to use on AWS?&lt;/li>
&lt;li>Which GPUs to consider for HPC use-cases?&lt;/li>
&lt;li>A complete and unapologetically detailed spreadsheet of all AWS GPU instances and their features&lt;/li>
&lt;/ol>
&lt;div class="td-card card border me-4">
&lt;div class="card-body">
&lt;h5 class="card-title">
Read the full blog post here: &lt;br>&lt;br> &lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">Choosing the right GPU for deep learning on AWS&lt;/a>&lt;/h5>
&lt;p class="card-text">
&lt;/p>
&lt;/div>
&lt;div class="card-footer">
&lt;img src="featured.png" alt="">&lt;/div>
&lt;/div></description></item></channel></rss>