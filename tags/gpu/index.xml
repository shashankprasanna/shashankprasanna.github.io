<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gpu on Shashank Prasanna</title><link>/tags/gpu/</link><description>Recent content in Gpu on Shashank Prasanna</description><generator>Hugo</generator><language>en</language><lastBuildDate>Wed, 11 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="/tags/gpu/index.xml" rel="self" type="application/rss+xml"/><item><title>What is an AI accelerator?</title><link>/what-is-an-ai-accelerator/</link><pubDate>Wed, 11 Jan 2023 00:00:00 +0000</pubDate><guid>/what-is-an-ai-accelerator/</guid><description>&lt;!-- ![](ai-hardware-spectrum-featured.png) -->
&lt;img src="ai-hardware-spectrum-featured.png" width="800"/>
&lt;p>An AI accelerator is a dedicated processor designed to accelerate machine learning computations. Machine learning, and particularly its subset, deep learning is primarily composed of a large number of linear algebra computations, (i.e. matrix-matrix, matrix-vector operations) and these operations can be easily parallelized. AI accelerators are specialized hardware designed to accelerate these basic machine learning computations and improve performance, reduce latency and reduce cost of deploying machine learning based applications.&lt;/p></description></item><item><title>AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution</title><link>/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/</link><pubDate>Fri, 09 Sep 2022 00:00:00 +0000</pubDate><guid>/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/</guid><description>&lt;p>If you told me a few years ago that data scientists would be using Docker containers in their day to day work, I wouldn’t have believed you. As a member of the broader machine learning (ML) community I always considered Docker, Kubernetes, Swarm (remember that?) exotic infrastructure tools for IT/Ops experts. Today it’s a different story, rarely a day goes by when I don’t use a Docker container for training or hosting a model.
An attribute of machine learning development that makes it different from traditional software development is that it relies on specialized hardware such as GPUs, Habana Gaudi, AWS Inferentia to accelerate training and inference. This makes it challenging to have containerized deployments that are hardware-agnostic, which is one of the key benefits of containers. In this blog post I’ll discuss how Docker and container technologies have evolved to address this challenge. We’ll discuss:&lt;/p></description></item><item><title>How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</title><link>/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/</link><pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate><guid>/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/</guid><description>&lt;p>If you told me a few years ago that data scientists would be using Docker containers in their day to day work, I wouldn’t have believed you. As a member of the broader machine learning (ML) community I always considered Docker, Kubernetes, Swarm (remember that?) exotic infrastructure tools for IT/Ops experts. Today it’s a different story, rarely a day goes by when I don’t use a Docker container for training or hosting a model.
An attribute of machine learning development that makes it different from traditional software development is that it relies on specialized hardware such as GPUs, Habana Gaudi, AWS Inferentia to accelerate training and inference. This makes it challenging to have containerized deployments that are hardware-agnostic, which is one of the key benefits of containers. In this blog post I’ll discuss how Docker and container technologies have evolved to address this challenge. We’ll discuss:&lt;/p></description></item><item><title>AWS GPU instances complete list</title><link>/complete-list-of-all-aws-gpu-instances/</link><pubDate>Thu, 02 Jun 2022 00:00:00 +0000</pubDate><guid>/complete-list-of-all-aws-gpu-instances/</guid><description>&lt;p>Here is a complete list of all Amazon EC2 GPU instance types on AWS that I&amp;rsquo;ve painstakenly compiled, because you can&amp;rsquo;t find this information anywhere on AWS.
In the tabular format below, you&amp;rsquo;ll find more detailed information about GPU type, interconnect, Thermal design power (TDP), precision types supported etc.&lt;/p>
&lt;div class="td-card card border me-4">
&lt;div class="card-body">
 &lt;h5 class="card-title">
 &lt;img src="https://miro.medium.com/v2/resize:fit:4800/format:webp/1*1qFKgyph2CT2Dxat3tSqmQ.png" alt="">&lt;/h5>
 &lt;p class="card-text">
 
&lt;/p>
 &lt;/div>
 &lt;div class="card-footer">
 From my blog post: &lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">Choosing the right GPU for deep learning on AWS&lt;/a>&lt;/div>
 &lt;/div>

&lt;h2 id="tabular-format">Tabular format&lt;/h2>
&lt;p>&lt;em>With more information than you were probably looking for&lt;/em> 😊&lt;/p></description></item><item><title>Best GPUs on AWS for Deep Learning</title><link>/best-gpus-on-aws-for-deep-learning/</link><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid>/best-gpus-on-aws-for-deep-learning/</guid><description>&lt;p>Here are 5 GPU instance recommendations on AWS that should serve majority of deep learning use-cases. For a complete deep dive into choosing the right GPU for deep learning on AWS, read my blog post:&lt;/p>


&lt;div class="alert alert-primary" role="alert">


 &lt;h3 id="choosing-the-right-gpu-for-deep-learning-on-aws">&lt;i class='fa-brands fa-medium'>&lt;/i> &lt;a href="https://medium.com/towards-data-science/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">Choosing the right GPU for deep learning on AWS&lt;/a>&lt;/h3>


&lt;/div>

&lt;div class="td-card card border me-4">
&lt;div class="card-header">
 &lt;strong>Highest performing multi-GPU instance on AWS&lt;/strong>
 &lt;/div>
&lt;div class="card-body">
 &lt;p class="card-text">
&lt;p>&lt;img src="/best-gpus-on-aws-for-deep-learning/gpu1.png" alt="GPU">&lt;/p>
&lt;p>&lt;strong>Instance: p4d.24xlarge&lt;/strong>&lt;/p>
&lt;p>&lt;strong>When to use it:&lt;/strong> When you need all the performance you can get. Use it for distributed training on large models and datasets.&lt;/p></description></item><item><title>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference</title><link>/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/</link><pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate><guid>/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/</guid><description>&lt;h3 id="lets-start-by-answering-the-question-what-is-an-ai-accelerator">Let’s start by answering the question “What is an AI accelerator?”&lt;/h3>
&lt;p>An AI accelerator is a dedicated processor designed to accelerate machine learning computations. Machine learning, and particularly its subset, deep learning is primarily composed of a large number of linear algebra computations, (i.e. matrix-matrix, matrix-vector operations) and these operations can be easily parallelized. AI accelerators are specialized hardware designed to accelerate these basic machine learning computations and improve performance, reduce latency and reduce cost of deploying machine learning based applications.&lt;/p></description></item><item><title>Choosing the right GPU for deep learning on AWS</title><link>/choosing-the-right-gpu-for-deep-learning-on-aws/</link><pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate><guid>/choosing-the-right-gpu-for-deep-learning-on-aws/</guid><description>&lt;p>On AWS, you can launch GPU instances with different GPU memory sizes (8 GB, 16 GB, 24 GB, 32 GB, 40 GB), NVIDIA GPU generations (Ampere, Turing, Volta, Maxwell, Kepler) different capabilities (FP64, FP32, FP16, INT8, Sparsity, TensorCores, NVLink), different number of GPUs per instance (1, 2, 4, 8, 16), and paired with different CPUs (Intel, AMD, Graviton2). You can also select instances with different vCPUs (core thread count), system memory and network bandwidth and add a range of storage options (object storage, network file systems, block storage, etc.) — in summary, you have options.&lt;/p></description></item></channel></rss>