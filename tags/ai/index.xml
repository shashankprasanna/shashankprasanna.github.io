<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Shashank Prasanna â€“ AI</title><link>https://shashankprasanna.com/tags/ai/</link><description>Recent content in AI on Shashank Prasanna</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 23 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://shashankprasanna.com/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Blog: Why I joined Modular AI?</title><link>https://shashankprasanna.com/why-i-joined-modular-ai/</link><pubDate>Fri, 23 Jun 2023 00:00:00 +0000</pubDate><guid>https://shashankprasanna.com/why-i-joined-modular-ai/</guid><description>
&lt;img src="https://shashankprasanna.com/why-i-joined-modular-ai/featured-background_hu0046ad040241532c6a31c60d96bfb17a_168182_640x0_resize_catmullrom_3.png" width="640" height="388"/>
&lt;p>&lt;img src="featured-background.png" alt="">
In the past decade, I&amp;rsquo;ve had the very good fortune of working for companies that make some of the best and proven developer productivity tools. If you&amp;rsquo;re an engineer who&amp;rsquo;s built control systems for rockets, cars or robots you&amp;rsquo;ve used MATLAB and Simulink. If you&amp;rsquo;re an AI developer you likely have an NVIDIA GPU at arm&amp;rsquo;s reach (ssh to AWS EC2 counts as arm&amp;rsquo;s reach). If you&amp;rsquo;re a developer running software in production you&amp;rsquo;ve likely relied on AWS services for their scalability and and reliability for deployment. If you&amp;rsquo;re an AI researcher there is no better tool than PyTorch to go from research paper to trained model.&lt;/p>
&lt;p>What these tools have in common is that they are individually, in my personal opinion, UNPARALLELED at what they do. However, when you start stringing multiple of these tools together, then their productivity promise breaks down. You already know this if you&amp;rsquo;re training custom models using some or all of these tools. I&amp;rsquo;ve spend the last several years talking about the the role of AI software and specialized AI hardware and the challenges with using multiple frameworks and AI accelerators during development and deployment and you can read about them &lt;a href="https://shashankprasanna.com/popular_blog_posts/">in my blog posts.&lt;/a>&lt;/p>
&lt;p>If you start AI development today, you&amp;rsquo;ll need answers to these questions before you start your project since it has huge implication on what tools you will use:&lt;/p>
&lt;div class="td-card card mb-4">
&lt;div class="card-header">
&lt;h5 id="during-prototyping-and-development">During prototyping and development&lt;/h5>
&lt;/div>
&lt;div class="card-body">
&lt;p class="card-text">
&lt;ol>
&lt;li>Should you decide on the framework ahead of time (PyTorch, TensorFlow,?)&lt;/li>
&lt;li>Should you decide where you&amp;rsquo;re going to run it later (GPU, TPU, Intel Habana, AWS Silicon etc.)?&lt;/li>
&lt;li>Should you write 5 versions of custom layer Op for each potential AI accelerators you want to target?&lt;/li>
&lt;li>Will your code run as-is when you go from laptop to cloud? on x86 and ARM CPUs? what about GPUs? What about other AI accelerators (AWS Silicon, Intel Habana Gaudi)?&lt;/li>
&lt;li>Will your code scale out of the box? will it scale on non-GPU AI accelerators? Will it work on all network hardware? between accelerators? between nodes?&lt;/li>
&lt;li>If you want to write non-ML code (e.g. data processing, control algorithm etc.) will that accelerate on CPUs, GPUs, AI Accelerators? What language do you write it in?&lt;/li>
&lt;/ol>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="td-card card mb-4">
&lt;div class="card-header">
&lt;h5 id="during-production-deployment">During production deployment&lt;/h5>
&lt;/div>
&lt;div class="card-body">
&lt;p class="card-text">
&lt;ol>
&lt;li>What serving framework will you use, was it designed for production or for AI research and prototyping&lt;/li>
&lt;li>Will it support multiple framework model formats?&lt;/li>
&lt;li>Does it run on x86, ARM, AI accelerators for inference?&lt;/li>
&lt;li>Can it run on embedded devices, what architectures are supported?&lt;/li>
&lt;li>Can it do model parallel on different AI accelerators?&lt;/li>
&lt;li>Can you meet your target throughput for desired latency at lower cost?&lt;/li>
&lt;li>Can you monitor performance and accuracy metrics?&lt;/li>
&lt;/ol>
&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>It&amp;rsquo;s exhausting isn&amp;rsquo;t it?&lt;/strong>&lt;/p>
&lt;p>The disadvantage of using disparate systems is that you risk months or years of reworking, re-tooling and re-implementing when something very small changes, such as - deciding to run on different hardware: GPUs and another AI accelerators, or implement custom models for multiple different frameworks or languages.&lt;/p>
&lt;p>Unfortunately, there aren&amp;rsquo;t a great solutions for these challenges today. What we need a very small, tight set of tools, that is performant, reliable that works well together, runs everywhere and is modular. You see where I&amp;rsquo;m going with this.&lt;/p>
&lt;h2 id="enter-modular-ai">Enter Modular AI&lt;/h2>
&lt;p>And that brings me to why I decided to join Modular. I share Modular co-founders Chris Lattner (LLVM, Swift) and Tim Davis&amp;rsquo;s vision that AI tools are &lt;strong>broken today and can be better&lt;/strong> and when fixed, can infinitely improve developer productivity. &lt;strong>AI tools can be more usable. AI tools can be more accessible. AI tools can make developers more productive which will make AI itself more accessible to everyone in the world.&lt;/strong> There will be a future when you don&amp;rsquo;t have to have answers to the questions ahead of time. You start your work, introduce different hardware, introduce custom models and extensions and stuff will just work. On any system. Deployed anywhere. And you only use one language. And deploy with one runtime engine.&lt;/p>
&lt;p>If I&amp;rsquo;ve piqued your interest, come check out the products we&amp;rsquo;re building at &lt;a href="https://www.modular.com/">Modular AI&lt;/a>:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>MojoðŸ”¥&lt;/strong> programming language that combines the usability of Python with the performance of C. You can write your custom kernels and ops in Mojo, so your entire stack that&amp;rsquo;ll run on multiple AI accelerators is in one language which is a superset of Python!&lt;/li>
&lt;li>&lt;strong>Modular Engine&lt;/strong> is an AI inference engine built with MojoðŸ”¥ that gives you unparalleled performance and runs PyTorch and TensorFlow models on multiple hardware.&lt;/li>
&lt;/ul>
&lt;p>Good tools make us productive, they bring us joy, the same joy you get when you find the right screw driver for that pesky loose screw, the right sized wrench, the right drill - no other makeshift tool will bring you that satisfaction of the right tool for the job. Practitioners in every domain need tools to build, create, solve, and implement more efficiently and AI is no different. &lt;strong>We need better AI tools for developers and I believe Modular will play a significant role in building them.&lt;/strong>&lt;/p>
&lt;p>We&amp;rsquo;re in early days, and Mojo and Modular Engine are not generally available yet, but you can try Mojo in the Mojo playground and see the performance speedups for yourself. &lt;a href="https://www.modular.com/get-started">Signup here to get access&lt;/a> to Mojo playground and learn more about other Modular products. Follow me on Twitter &lt;a href="https://twitter.com/shshnkp">@shshnkp&lt;/a>, read my blog posts on Medium (and here) &lt;a href="https://medium.com/@shashankprasanna">@shashank.prasanna&lt;/a> and connect with me on &lt;a href="https://www.linkedin.com/in/shashankprasanna/">LinkedIn&lt;/a> as I&amp;rsquo;ll be sharing a Modular&amp;rsquo;s journey and educational content. Thanks for reading!&lt;/p></description></item><item><title>Blog: Automatically generate code and documentation using OpenAI CODEX</title><link>https://shashankprasanna.com/automatically-generate-code-and-documentation-using-openai-codex/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://shashankprasanna.com/automatically-generate-code-and-documentation-using-openai-codex/</guid><description>
&lt;img src="https://shashankprasanna.com/automatically-generate-code-and-documentation-using-openai-codex/screenshot8-featured_huc7ef144ea84a250195ff19b8f35ca83f_78825_640x0_resize_catmullrom_3.png" width="640" height="271"/>
&lt;p>We&amp;rsquo;ve all dealt with the frustration of poor or incomplete documentation in software projects. In their &lt;a href="https://octoverse.github.com/creating-documentation/">2021 state of the Octoverse survey&lt;/a>, GitHub found that easy to use documentation, boosted developer productivity by 50% and improved contribution quality, yet it continues to be an under-invested area across open-source projects.&lt;/p>
&lt;p>Using OpenAI Codex you can use to automatically edit existing code to add documentation using only natural language instructions. This new feature will let you spend more time developing new features and reviewing generated documentation instead of writing documentation from scratch. In addition to generating documentation, Codex&amp;rsquo;s edit feature can refactor code, update logic, translate between programming languages and change coding styles.&lt;/p>
&lt;p>In this blog post, we&amp;rsquo;ll take a look at how Codex edit feature works through a code example. One of my favorite areas of machine learning (ML) research is automated machine learning (AutoML) or low-code ML. I&amp;rsquo;ll use Codex to implement a simple data science workflow only using natural language instructions and without writing any ML code. We&amp;rsquo;ll perform the following steps only using Codex&amp;rsquo;s Edit API and discuss its features as we implement the code example:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Generate python code to load a dataset and visualize it&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Generate python code to train a machine learning classifier on the dataset&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Edit generated code to customize it for the specific problem dataset&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Edit updated code to add detailed documentation&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Sounds exciting? Let&amp;rsquo;s get started!&lt;/p>
&lt;h2 id="using-openai-codex-edit-feature-to-generate-fully-documented-code-to-train-a-classifier-on-a-tabular-dataset">Using OpenAI Codex edit feature to generate fully documented code to train a classifier on a tabular dataset&lt;/h2>
&lt;p>Let&amp;rsquo;s use OpenAI Codex to solve the &lt;a href="https://www.kaggle.com/c/titanic/data">Titanic - Machine Learning from Disaster&lt;/a> Kaggle competition. The titanic dataset consists of passenger information like name, age, gender, etc. and if they survived the disaster or not. We&amp;rsquo;ll use natural language prompts to iteratively build code and documentation. To download the dataset, you&amp;rsquo;ll need to create a free Kaggle account and download it either via the web page or by following the instructions on the &lt;a href="https://github.com/Kaggle/kaggle-api">Kaggle API GitHub page&lt;/a>.&lt;/p>
&lt;p>Next, you&amp;rsquo;ll need an Open AI account. If you&amp;rsquo;re new to OpenAI, head over to &lt;a href="https://openai.com/api/login/">https://openai.com/api/login/&lt;/a> and create your free trial account. This will give you access to $18 in free credit that you can use for upto 3 months.&lt;/p>
&lt;p>After you&amp;rsquo;ve created your account, you&amp;rsquo;ll have access to your unique API keys that you can use to invoke the OpenAI API using the official &lt;a href="https://beta.openai.com/docs/libraries/python-bindings">Python&lt;/a>, Node.js or any of the &lt;a href="https://beta.openai.com/docs/libraries/community-libraries">community supported libraries&lt;/a>. Since our example generates Python code, we&amp;rsquo;ll use the Python bindings.&lt;/p>
&lt;h3 id="step-1-setting-up-openai-python-package">Step 1: Setting up OpenAI Python package&lt;/h3>
&lt;p>Open your favorite IDE to get started, I prefer Jupyter Lab as it&amp;rsquo;s the most popular IDE used by data scientists. Import openai Python package and specify your organization and API keys. You can find these on your Open AI account.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> os
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> openai
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openai&lt;span style="color:#f92672">.&lt;/span>organization &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;org-XXXXXXXXXXXXXXX&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>openai&lt;span style="color:#f92672">.&lt;/span>api_key &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;sk-XXXXXXXXXXXXXXXX&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="step-2-generate-python-code-to-load-an-analyze-the-dataset">Step 2: Generate python code to load an analyze the dataset&lt;/h3>
&lt;p>We can use the Codex edit feature to edit existing code or generate new code. Let&amp;rsquo;s start by generating some fresh code to load our Titanic CSV dataset and analyze it.&lt;/p>
&lt;p>Here&amp;rsquo;s what the arguments to the create() function mean:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Input&lt;/strong>: Provide a prompt as a starting point. We leave it empty since we&amp;rsquo;re going to generate new code and not edit existing code.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Instructions&lt;/strong>: Provide instructions to Codex on what code to generate. Here we describe that we want to generate code to load and analyze our CSV dataset.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Engine&lt;/strong>: Provide the engine for Codex edit feature, the latest name and version is &lt;code>Code-davinci-edit-001&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Temperature&lt;/strong> and &lt;strong>top_p&lt;/strong>: used to control how deterministic the model is in generating a response. I choose a lower value for top_p (=0.2) to get a consistent response.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>You can find more information about the API in the &lt;a href="https://beta.openai.com/docs/api-reference/edits/create">Edits documentation&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> IPython.display &lt;span style="color:#f92672">import&lt;/span> display
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>input_prompt &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>instruction &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Write python function to load a CSV file called titanic.csv into a dataframe and use display function&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> openai&lt;span style="color:#f92672">.&lt;/span>Edit&lt;span style="color:#f92672">.&lt;/span>create(input&lt;span style="color:#f92672">=&lt;/span>input_prompt,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> instruction&lt;span style="color:#f92672">=&lt;/span>instruction,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> engine&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;code-davinci-edit-001&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> temperature&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> top_p&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.2&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Output:&lt;/strong>&lt;/p>
&lt;p>When you run the code, you should see an output that looks like the screenshot below. From the output we can see that the dataset has both numeric and categorical variables. This information will come in handy later when we ask Codex to edit our function. For now, let&amp;rsquo;s continue to build on this program to classify the dataset.&lt;/p>
&lt;p>&lt;img src="screenshot1.png" alt="">&lt;/p>
&lt;h3 id="step-3-generate-a-python-program-to-classify-the-dataset">Step 3: Generate a Python program to classify the dataset&lt;/h3>
&lt;p>In this step, rather than leave the input prompt empty, let&amp;rsquo;s provide the function signature we expect so Codex can fill out the rest of the program. Under instructions we provide:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Write python function to load a CSV file and perform binary XGBoost classification on a target column:&lt;/li>
&lt;/ul>
&lt;p>Extending our previous example, we&amp;rsquo;ll ask Codex to generate a program to use XGBoost to classify our dataset based on a specified target variable. If you&amp;rsquo;re new to machine learning, XGBoost is a fantastic works-out-of-the-box classifier for tabular datasets that often requires little to no fine tuning to get acceptable results.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>input_prompt &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">def csv_classification(csv_file, target_column):
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>instruction &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Write python function to load a CSV file and perform binary XGBoost classification on a target column&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> openai&lt;span style="color:#f92672">.&lt;/span>Edit&lt;span style="color:#f92672">.&lt;/span>create(input&lt;span style="color:#f92672">=&lt;/span>input_prompt,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> instruction&lt;span style="color:#f92672">=&lt;/span>instruction,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> engine&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;code-davinci-edit-001&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> temperature&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> top_p&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>generated_code &lt;span style="color:#f92672">=&lt;/span> response[&lt;span style="color:#e6db74">&amp;#34;choices&amp;#34;&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(generated_code)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Output:&lt;/strong>&lt;/p>
&lt;p>Codex generates the following code to classify our dataset using XGBoost. If you&amp;rsquo;re new to machine learning, let&amp;rsquo;s just take a moment to appreciate how much time we saved by having Codex generate this vs. writing this from scratch. We still need to test if this code works, so let&amp;rsquo;s go ahead and do that in the next step.&lt;/p>
&lt;p>&lt;img src="screenshot2.png" alt="">&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>exec(generated_code)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>csv_classification(&lt;span style="color:#e6db74">&amp;#39;titanic.csv&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Survived&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Output:&lt;/strong>&lt;/p>
&lt;p>Oh no! the generated code throws an error! Not what we want to see, but let&amp;rsquo;s take a closer look at the error message. The error message says:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>We have categorical variables that need to be specified as categorical variables. If we go back to the output of Step 1, we can verify from that the Name, Sex, Ticket, Cabin and Embarked are indeed categorical.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Since we have categorical variables, we need to instruct XGBoost to enable categorical support using `enable_categorical` argument.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>To remedy this, let&amp;rsquo;s make Codex do all the hard work by simply copying the error message and including it in the instructions of the next step.&lt;/p>
&lt;p>&lt;img src="screenshot3.png" alt="">&lt;/p>
&lt;h3 id="step-4-fixing-errors-in-the-generated-code-by-updating-the-instructions">Step 4: Fixing errors in the generated code by updating the instructions&lt;/h3>
&lt;p>In this step, we start with the generated code from Step 3, and provide instructions to make changes specified in the error message. We provide the following instructions:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Update code to set dataframe columns Name, Sex, Ticket, Cabin, Embarked to categorical and set DMatrix parameter 'enable_categorical' to 'True'&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>input_prompt &lt;span style="color:#f92672">=&lt;/span> generated_code
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>instruction &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Update code to set dataframe columns Name, Sex, Ticket, Cabin, Embarked to categorical and set DMatrix parameter &amp;#39;enable_categorical&amp;#39; to &amp;#39;True&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> openai&lt;span style="color:#f92672">.&lt;/span>Edit&lt;span style="color:#f92672">.&lt;/span>create(input&lt;span style="color:#f92672">=&lt;/span>input_prompt,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> instruction&lt;span style="color:#f92672">=&lt;/span>instruction,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> engine&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;code-davinci-edit-001&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> temperature&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> top_p&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>generated_code &lt;span style="color:#f92672">=&lt;/span> response[&lt;span style="color:#e6db74">&amp;#34;choices&amp;#34;&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(generated_code)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Output:&lt;/strong>&lt;/p>
&lt;p>This generates updated code that addresses the categorical variable errors by converting the specified column into categorical and by setting enable_categorical to True when creating the XGBoost&amp;rsquo;s native DMatrix data structure. Again let&amp;rsquo;s take a moment to appreciate how little we had to do to generate code for a generic tabular data classifier using XGBoost.&lt;/p>
&lt;p>&lt;img src="screenshot4.png" alt="">&lt;/p>
&lt;p>Let&amp;rsquo;s go ahead and execute this code to train our classifier:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>exec(generated_code)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>csv_classification(&lt;span style="color:#e6db74">&amp;#39;titanic.csv&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Survived&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Output:&lt;/strong>&lt;/p>
&lt;p>Sure enough, our code now runs without any issues and trains the classifier to 83% accuracy on the test set. Note that this is a very simple dataset, but the generated code can now be used for a number of tabular classification problems. Need to modify the code to change features? Just repeat the instructions in this step to specify what needs to be updated.&lt;/p>
&lt;p>&lt;img src="screenshot5.png" alt="">&lt;/p>
&lt;h3 id="step-5-generate-detailed-documentation">Step 5: Generate detailed documentation&lt;/h3>
&lt;p>Finally, let&amp;rsquo;s use the generated code and add detailed documentation to it using Codex. To do that we provide natural language instructions on how and where to add comments:&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Add a detailed paragraph at the top of the code describing what the code is doing, and add detailed comments explaining every line of code&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>instruction &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">Add a detailed paragraph at the top of the code describing what the code is doing, and add detailed comments explaining every line of code
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>response &lt;span style="color:#f92672">=&lt;/span> openai&lt;span style="color:#f92672">.&lt;/span>Edit&lt;span style="color:#f92672">.&lt;/span>create(input&lt;span style="color:#f92672">=&lt;/span>generated_code,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> instruction&lt;span style="color:#f92672">=&lt;/span>instruction,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> engine&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;code-davinci-edit-001&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> temperature&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> top_p&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0.2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>documented_code &lt;span style="color:#f92672">=&lt;/span> response[&lt;span style="color:#e6db74">&amp;#34;choices&amp;#34;&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(documented_code)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Output:&lt;/strong>&lt;/p>
&lt;p>Here you can see the detailed description of the full program, you can also see that the additional comments were automatically added under the function definition describing each line of code.&lt;/p>
&lt;p>&lt;img src="screenshot6.png" alt="">&lt;/p>
&lt;p>If you&amp;rsquo;re new to XGBoost, you can also use the generated documentation to learn about what each of the hyperparameters mean! Now you know that eta is actually the learning rate, and max_depth is the maximum depth of each of the 20 trees XGBoost uses. How cool is that?&lt;/p>
&lt;p>&lt;img src="screenshot7.png" alt="">&lt;/p>
&lt;p>We now have a fully functional and documented code that you can use to submit your results to the Titanic Kaggle competition!&lt;/p>
&lt;h2 id="now-its-your-turn">Now it&amp;rsquo;s your turn!&lt;/h2>
&lt;p>If this piqued your interest head on over to &lt;a href="https://openai.com/api/login/">https://openai.com/api/login/&lt;/a> and create your free trial account. I&amp;rsquo;m making all the code used in this blog post is available as a Jupyter notebook on GitHub so you can run the entire example with a single click&lt;/p>
&lt;p>Now it&amp;rsquo;s your turn! How will you use Codex&amp;rsquo;s new edit feature? Let me know by reaching out to me at &lt;a href="https://twitter.com/shshnkp">@shshnkp&lt;/a>
&lt;img src="screenshot8-featured.png" alt="">&lt;/p></description></item></channel></rss>