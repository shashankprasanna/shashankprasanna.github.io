<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.118.2"><link rel=alternate type=application/rss+xml href=https://shashankprasanna.com/blog/index.xml><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Blog | Shashank Prasanna</title><meta name=description content="Shashank Prasanna's personal website"><meta property="og:title" content="Blog"><meta property="og:description" content="Shashank Prasanna's personal website"><meta property="og:type" content="website"><meta property="og:url" content="https://shashankprasanna.com/blog/"><meta itemprop=name content="Blog"><meta itemprop=description content="Shashank Prasanna's personal website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Shashank Prasanna's personal website"><link rel=preload href=/scss/main.min.69537fa29b588a0489895f73e23bb15ef971d18488cb8464157b4024198e733a.css as=style><link href=/scss/main.min.69537fa29b588a0489895f73e23bb15ef971d18488cb8464157b4024198e733a.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-20Q10LSLZ7"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-20Q10LSLZ7")}</script></head><body class="td-section td-blog"><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>Shashank Prasanna</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/><span class=active>Home</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://medium.com/@shashankprasanna target=_blank><i class='fa-brands fa-medium'></i><span>Medium+TDS</span><sup><i class='ps-1 fa-solid fa-up-right-from-square fa-xs' aria-hidden=true></i></sup></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/blog/><span class=active>Blog</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.fa5f0e32757eea382b7d62174d552e1f.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.fa5f0e32757eea382b7d62174d552e1f.json data-offline-search-base-href=/ data-offline-search-max-results=10></div><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-blog-li><a href=/blog/ class="align-left pl-0 active td-sidebar-link td-sidebar-link__section tree-root" id=m-blog><span class=td-sidebar-nav-active-item>Blog</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-why-i-joined-modular-ai-li><a href=/why-i-joined-modular-ai/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-why-i-joined-modular-ai><span>Why I joined Modular AI?</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-benchmarking-modular-mojo-and-pytorch-torchcompile-on-mandelbrot-function-li><a href=/benchmarking-modular-mojo-and-pytorch-torch.compile-on-mandelbrot-function/ title="Benchmarking Modular Mojo🔥 and PyTorch torch.compile() on Mandelbrot function" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-benchmarking-modular-mojo-and-pytorch-torchcompile-on-mandelbrot-function><span>Benchmarking Modular Mojo and PyTorch torch.compile() on Mandelbrot function</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-how-pytorch-20-accelerates-deep-learning-with-operator-fusion-and-cpugpu-code-generation-li><a href=/how-pytorch-2.0-accelerates-deep-learning-with-operator-fusion-and-cpu/gpu-code-generation/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-how-pytorch-20-accelerates-deep-learning-with-operator-fusion-and-cpugpu-code-generation><span>How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution-li><a href=/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution><span>AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators-li><a href=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators><span>How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-automatically-generate-code-and-documentation-using-openai-codex-li><a href=/automatically-generate-code-and-documentation-using-openai-codex/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-automatically-generate-code-and-documentation-using-openai-codex><span>Automatically generate code and documentation using OpenAI CODEX</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference-li><a href=/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference><span>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-choosing-the-right-gpu-for-deep-learning-on-aws-li><a href=/choosing-the-right-gpu-for-deep-learning-on-aws/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-choosing-the-right-gpu-for-deep-learning-on-aws><span>Choosing the right GPU for deep learning on AWS</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><div class=box><img style=vertical-align:middle src=https://shashankprasanna.com/featured-background.png alt="shashank prasanna" width=200></div><a href=https://github.com/shashankprasanna/shashankprasanna.com/tree/main/content/en/blog/_index.md class=td-page-meta--view target=_blank rel=noopener><i class="fa fa-file-alt fa-fw"></i> View page source</a>
<a href=https://github.com/shashankprasanna/shashankprasanna.com/edit/main/content/en/blog/_index.md class=td-page-meta--edit target=_blank rel=noopener><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="https://github.com/shashankprasanna/shashankprasanna.com/new/main/content/en/blog/_index.md?filename=change-me.md&amp;value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" class=td-page-meta--child target=_blank rel=noopener><i class="fa fa-edit fa-fw"></i> Create child page</a>
<a href="https://github.com/shashankprasanna/shashankprasanna.com/issues/new?title=Blog" class=td-page-meta--issue target=_blank rel=noopener><i class="fas fa-tasks fa-fw"></i> Create documentation issue</a>
<a href=https://github.com/shashankprasanna/shashankprasanna.com/issues/new class=td-page-meta--project-issue target=_blank rel=noopener><i class="fas fa-tasks fa-fw"></i> Create project issue</a></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role=main><font color=black size=5></font>
<a class=td-rss-button title=RSS href=https://shashankprasanna.com/blog/index.xml target=_blank rel=noopener><i class="fa-solid fa-rss" aria-hidden=true></i></a><div class=row><div class=col-12><h2>Posts in 2023</h2><ul class="list-unstyled mt-4"><li class="media mb-4"><div class=media-body><h5 class="mt-0 mb-1"><a href=/why-i-joined-modular-ai/>Why I joined Modular AI?</a></h5><p class="mb-2 mb-md-3"><small class=text-muted>Friday, June 23, 2023 in Blog</small></p><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/modular/ data-taxonomy-term=modular><span class=taxonomy-label>modular</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/mojo/ data-taxonomy-term=mojo><span class=taxonomy-label>mojo</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/ai/ data-taxonomy-term=ai><span class=taxonomy-label>AI</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/career/ data-taxonomy-term=career><span class=taxonomy-label>career</span></a></li></ul></div></header><figure class="float-left mr-3 pt-1 d-none d-md-block" style=width:250px><img src=/why-i-joined-modular-ai/featured-background_hu0046ad040241532c6a31c60d96bfb17a_168182_250x125_fill_catmullrom_smart1_3.png alt="Featured Image for Why I joined Modular AI?" width=250 height=125></figure><p class="pt-0 mt-0">In the past decade, I&rsquo;ve had the very good fortune of working for companies that make some of the best and proven developer productivity tools. If you&rsquo;re an engineer who&rsquo;s built control systems for rockets, cars or robots …</p><p class=pt-0><a href=/why-i-joined-modular-ai/ aria-label="Read more - Why I joined Modular AI?">Read more</a></p></div></li><li class="media mb-4"><div class=media-body><h5 class="mt-0 mb-1"><a href=/benchmarking-modular-mojo-and-pytorch-torch.compile-on-mandelbrot-function/>Benchmarking Modular Mojo🔥 and PyTorch torch.compile() on Mandelbrot function</a></h5><p class="mb-2 mb-md-3"><small class=text-muted>Monday, May 08, 2023 in Blog</small></p><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/pytorch/ data-taxonomy-term=pytorch><span class=taxonomy-label>pytorch</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/modular/ data-taxonomy-term=modular><span class=taxonomy-label>modular</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/mojo/ data-taxonomy-term=mojo><span class=taxonomy-label>mojo</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/mandelbrot/ data-taxonomy-term=mandelbrot><span class=taxonomy-label>mandelbrot</span></a></li></ul></div></header><figure class="float-left mr-3 pt-1 d-none d-md-block" style=width:250px><img src=/benchmarking-modular-mojo-and-pytorch-torch.compile-on-mandelbrot-function/featured-background_hu52d0dfd7da44399cff6626242a002e0e_3253184_250x125_fill_catmullrom_smart1_3.png alt="Featured Image for Benchmarking Modular Mojo🔥 and PyTorch torch.compile() on Mandelbrot function" width=250 height=125></figure><p class="pt-0 mt-0">Last week, Modular - an startup co-founded by Chris Lattner (of LLVM, Swift, MLIR fame), announced a brand new high-performance language called Mojo🔥. Mojo🔥 looks and reads like Python but that&rsquo;s only on the surface, underneath the familiar …</p><p class=pt-0><a href=/benchmarking-modular-mojo-and-pytorch-torch.compile-on-mandelbrot-function/ aria-label="Read more - Benchmarking Modular Mojo and PyTorch torch.compile() on Mandelbrot function">Read more</a></p></div></li><li class="media mb-4"><div class=media-body><h5 class="mt-0 mb-1"><a href=/how-pytorch-2.0-accelerates-deep-learning-with-operator-fusion-and-cpu/gpu-code-generation/>How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation</a></h5><p class="mb-2 mb-md-3"><small class=text-muted>Sunday, April 30, 2023 in Blog</small></p><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/pytorch/ data-taxonomy-term=pytorch><span class=taxonomy-label>pytorch</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/compiler/ data-taxonomy-term=compiler><span class=taxonomy-label>compiler</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/ir/ data-taxonomy-term=ir><span class=taxonomy-label>IR</span></a></li></ul></div></header><figure class="float-left mr-3 pt-1 d-none d-md-block" style=width:250px><img src=/how-pytorch-2.0-accelerates-deep-learning-with-operator-fusion-and-cpu/gpu-code-generation/featured_hu0fb5b15bba115eaa0a2341edd31b99b2_23922_250x125_fill_catmullrom_smart1_3.png alt="Featured Image for How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation" width=250 height=125></figure><p class="pt-0 mt-0">Computer programming is magical. We write code in human readable languages, and as though by magic, it gets translated into electric currents through silicon transistors making them behave like switches and allowing them to implement complex logic — …</p><p class=pt-0><a href=/how-pytorch-2.0-accelerates-deep-learning-with-operator-fusion-and-cpu/gpu-code-generation/ aria-label="Read more - How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation">Read more</a></p></div></li></ul><h2>Posts in 2022</h2><ul class="list-unstyled mt-4"><li class="media mb-4"><div class=media-body><h5 class="mt-0 mb-1"><a href=/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/>AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution</a></h5><p class="mb-2 mb-md-3"><small class=text-muted>Friday, September 09, 2022 in Blog</small></p><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/ai-accelerators/ data-taxonomy-term=ai-accelerators><span class=taxonomy-label>ai accelerators</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/gpu/ data-taxonomy-term=gpu><span class=taxonomy-label>gpu</span></a></li></ul></div></header><figure class="float-left mr-3 pt-1 d-none d-md-block" style=width:250px><img src=/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/featured_hu153888cb09e42ad7fc9ab1679dae3388_33262_250x125_fill_catmullrom_smart1_3.png alt="Featured Image for AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution" width=250 height=125></figure><p class="pt-0 mt-0">If you told me a few years ago that data scientists would be using Docker containers in their day to day work, I wouldn’t have believed you. As a member of the broader machine learning (ML) community I always considered Docker, Kubernetes, Swarm …</p><p class=pt-0><a href=/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/ aria-label="Read more - AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution">Read more</a></p></div></li><li class="media mb-4"><div class=media-body><h5 class="mt-0 mb-1"><a href=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/>How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</a></h5><p class="mb-2 mb-md-3"><small class=text-muted>Wednesday, August 24, 2022 in Blog</small></p><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/docker/ data-taxonomy-term=docker><span class=taxonomy-label>docker</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/gpu/ data-taxonomy-term=gpu><span class=taxonomy-label>gpu</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/aws/ data-taxonomy-term=aws><span class=taxonomy-label>aws</span></a></li></ul></div></header><figure class="float-left mr-3 pt-1 d-none d-md-block" style=width:250px><img src=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/featured_hu40258b408388e57d94159bf91c739a7c_102531_250x125_fill_catmullrom_smart1_3.png alt="Featured Image for How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators" width=250 height=125></figure><p class="pt-0 mt-0">If you told me a few years ago that data scientists would be using Docker containers in their day to day work, I wouldn’t have believed you. As a member of the broader machine learning (ML) community I always considered Docker, Kubernetes, Swarm …</p><p class=pt-0><a href=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/ aria-label="Read more - How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators">Read more</a></p></div></li><li class="media mb-4"><div class=media-body><h5 class="mt-0 mb-1"><a href=/automatically-generate-code-and-documentation-using-openai-codex/>Automatically generate code and documentation using OpenAI CODEX</a></h5><p class="mb-2 mb-md-3"><small class=text-muted>Monday, August 01, 2022 in Blog</small></p><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/openai/ data-taxonomy-term=openai><span class=taxonomy-label>openai</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/codex/ data-taxonomy-term=codex><span class=taxonomy-label>codex</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/ai/ data-taxonomy-term=ai><span class=taxonomy-label>AI</span></a></li></ul></div></header><figure class="float-left mr-3 pt-1 d-none d-md-block" style=width:250px><img src=/automatically-generate-code-and-documentation-using-openai-codex/screenshot8-featured_huc7ef144ea84a250195ff19b8f35ca83f_78825_250x125_fill_catmullrom_smart1_3.png alt="Featured Image for Automatically generate code and documentation using OpenAI CODEX" width=250 height=125></figure><p class="pt-0 mt-0">We&rsquo;ve all dealt with the frustration of poor or incomplete documentation in software projects. In their 2021 state of the Octoverse survey, GitHub found that easy to use documentation, boosted developer productivity by 50% and improved …</p><p class=pt-0><a href=/automatically-generate-code-and-documentation-using-openai-codex/ aria-label="Read more - Automatically generate code and documentation using OpenAI CODEX">Read more</a></p></div></li></ul><h2>Posts in 2020</h2><ul class="list-unstyled mt-4"><li class="media mb-4"><div class=media-body><h5 class="mt-0 mb-1"><a href=/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference</a></h5><p class="mb-2 mb-md-3"><small class=text-muted>Wednesday, October 21, 2020 in Blog</small></p><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/ai-accelerators/ data-taxonomy-term=ai-accelerators><span class=taxonomy-label>ai accelerators</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/gpu/ data-taxonomy-term=gpu><span class=taxonomy-label>gpu</span></a></li></ul></div></header><figure class="float-left mr-3 pt-1 d-none d-md-block" style=width:250px><img src=/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/featured_hu153888cb09e42ad7fc9ab1679dae3388_33262_250x125_fill_catmullrom_smart1_3.png alt="Featured Image for A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference" width=250 height=125></figure><p class="pt-0 mt-0">Let’s start by answering the question “What is an AI accelerator?” An AI accelerator is a dedicated processor designed to accelerate machine learning computations. Machine learning, and particularly its subset, deep learning is primarily composed of …</p><p class=pt-0><a href=/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/ aria-label="Read more - A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference">Read more</a></p></div></li><li class="media mb-4"><div class=media-body><h5 class="mt-0 mb-1"><a href=/choosing-the-right-gpu-for-deep-learning-on-aws/>Choosing the right GPU for deep learning on AWS</a></h5><p class="mb-2 mb-md-3"><small class=text-muted>Thursday, June 25, 2020 in Blog</small></p><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/aws/ data-taxonomy-term=aws><span class=taxonomy-label>aws</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/gpu/ data-taxonomy-term=gpu><span class=taxonomy-label>gpu</span></a></li></ul></div></header><figure class="float-left mr-3 pt-1 d-none d-md-block" style=width:250px><img src=/choosing-the-right-gpu-for-deep-learning-on-aws/featured_hu3cf755c2b3f91847dc184a8c7feac088_100672_250x125_fill_catmullrom_smart1_3.png alt="Featured Image for Choosing the right GPU for deep learning on AWS" width=250 height=125></figure><p class="pt-0 mt-0">On AWS, you can launch GPU instances with different GPU memory sizes (8 GB, 16 GB, 24 GB, 32 GB, 40 GB), NVIDIA GPU generations (Ampere, Turing, Volta, Maxwell, Kepler) different capabilities (FP64, FP32, FP16, INT8, Sparsity, TensorCores, NVLink), …</p><p class=pt-0><a href=/choosing-the-right-gpu-for-deep-learning-on-aws/ aria-label="Read more - Choosing the right GPU for deep learning on AWS">Read more</a></p></div></li></ul></div></div><div class="row pl-2 pt-2"><div class=col></div></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://twitter.com/shshnkp aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=LinkedIn aria-label=LinkedIn><a class=text-white target=_blank rel=noopener href=https://www.linkedin.com/in/shashankprasanna/ aria-label=LinkedIn><i class="fab fa-linkedin"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/shashankprasanna/ aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=YouTube aria-label=YouTube><a class=text-white target=_blank rel=noopener href=https://www.youtube.com/@shashank.prasanna aria-label=YouTube><i class="fab fa-youtube"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Medium aria-label=Medium><a class=text-white target=_blank rel=noopener href=https://medium.com/@shashankprasanna aria-label=Medium><i class="fab fa-medium"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2023 Shashank Prasanna All Rights Reserved</small></div></div></div></footer></div><script src=/js/main.min.2aff983e9d0d8ecff9ed53e14b657216e2d8d2aff059bf4a5651283020995f1b.js integrity="sha256-Kv+YPp0Njs/57VPhS2VyFuLY0q/wWb9KVlEoMCCZXxs=" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script></body></html>