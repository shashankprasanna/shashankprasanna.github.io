<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.114.1"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution | Shashank Prasanna</title><meta name=description content="Efficient algorithms and methods in machine learning for AI accelerators ‚Äî NVIDIA GPUs, Intel Habana Gaudi and AWS Trainium and Inferentia"><meta property="og:title" content="AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution"><meta property="og:description" content="Efficient algorithms and methods in machine learning for AI accelerators ‚Äî NVIDIA GPUs, Intel Habana Gaudi and AWS Trainium and Inferentia"><meta property="og:type" content="article"><meta property="og:url" content="https://shashankprasanna.com/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/"><meta property="og:image" content="https://shashankprasanna.com/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/featured.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2022-09-09T00:00:00+00:00"><meta property="article:modified_time" content="2022-09-09T00:00:00+00:00"><meta itemprop=name content="AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution"><meta itemprop=description content="Efficient algorithms and methods in machine learning for AI accelerators ‚Äî NVIDIA GPUs, Intel Habana Gaudi and AWS Trainium and Inferentia"><meta itemprop=datePublished content="2022-09-09T00:00:00+00:00"><meta itemprop=dateModified content="2022-09-09T00:00:00+00:00"><meta itemprop=wordCount content="247"><meta itemprop=image content="https://shashankprasanna.com/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/featured.png"><meta itemprop=keywords content="ai accelerators,gpu,"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shashankprasanna.com/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/featured.png"><meta name=twitter:title content="AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution"><meta name=twitter:description content="Efficient algorithms and methods in machine learning for AI accelerators ‚Äî NVIDIA GPUs, Intel Habana Gaudi and AWS Trainium and Inferentia"><link rel=preload href=/scss/main.min.4ebc9c302abc169c889c20c62ea5446819b4072c23214987200e11c43ffd2f03.css as=style><link href=/scss/main.min.4ebc9c302abc169c889c20c62ea5446819b4072c23214987200e11c43ffd2f03.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-20Q10LSLZ7"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-20Q10LSLZ7")}</script></head><body class="td-page td-blog"><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>Shashank Prasanna</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/><span class=active>Home</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://medium.com/@shashankprasanna target=_blank><i class='fa-brands fa-medium'></i><span>Medium+TDS</span><sup><i class='ps-1 fa-solid fa-up-right-from-square fa-xs' aria-hidden=true></i></sup></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/blog/><span class=active>Blog</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site‚Ä¶" aria-label="Search this site‚Ä¶" autocomplete=off data-offline-search-index-json-src=/offline-search-index.7adb28cd8da1d18a6eed7784d1f50d91.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site‚Ä¶" aria-label="Search this site‚Ä¶" autocomplete=off data-offline-search-index-json-src=/offline-search-index.7adb28cd8da1d18a6eed7784d1f50d91.json data-offline-search-base-href=/ data-offline-search-max-results=10></div><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-blog-li><a href=/blog/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-blog><span>Blog</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-why-i-joined-modular-ai-li><a href=/why-i-joined-modular-ai/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-why-i-joined-modular-ai><span>Why I joined Modular AI?</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-benchmarking-modular-mojo-and-pytorch-torchcompile-on-mandelbrot-function-li><a href=/benchmarking-modular-mojo-and-pytorch-torch.compile-on-mandelbrot-function/ title="Benchmarking Modular Mojoüî• and PyTorch torch.compile() on Mandelbrot function" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-benchmarking-modular-mojo-and-pytorch-torchcompile-on-mandelbrot-function><span>Benchmarking Modular Mojo and PyTorch torch.compile() on Mandelbrot function</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-how-pytorch-20-accelerates-deep-learning-with-operator-fusion-and-cpugpu-code-generation-li><a href=/how-pytorch-2.0-accelerates-deep-learning-with-operator-fusion-and-cpu/gpu-code-generation/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-how-pytorch-20-accelerates-deep-learning-with-operator-fusion-and-cpugpu-code-generation><span>How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution-li><a href=/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/ class="align-left pl-0 active td-sidebar-link td-sidebar-link__page" id=m-ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution><span class=td-sidebar-nav-active-item>AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators-li><a href=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators><span>How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-automatically-generate-code-and-documentation-using-openai-codex-li><a href=/automatically-generate-code-and-documentation-using-openai-codex/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-automatically-generate-code-and-documentation-using-openai-codex><span>Automatically generate code and documentation using OpenAI CODEX</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference-li><a href=/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference><span>A complete guide to AI accelerators for deep learning inference ‚Äî GPUs, AWS Inferentia and Amazon Elastic Inference</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-choosing-the-right-gpu-for-deep-learning-on-aws-li><a href=/choosing-the-right-gpu-for-deep-learning-on-aws/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-choosing-the-right-gpu-for-deep-learning-on-aws><span>Choosing the right GPU for deep learning on AWS</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><div class=box><img style=vertical-align:middle src=https://shashankprasanna.com/featured-background.png alt="shashank prasanna" width=200></div><a href=https://github.com/shashankprasanna/shashankprasanna.com/tree/main/content/en/blog/AI%20Accelerators%20and%20Machine%20Learning%20Algorithms:%20Co-Design%20and%20Evolution/index.md class=td-page-meta--view target=_blank rel=noopener><i class="fa fa-file-alt fa-fw"></i> View page source</a>
<a href=https://github.com/shashankprasanna/shashankprasanna.com/edit/main/content/en/blog/AI%20Accelerators%20and%20Machine%20Learning%20Algorithms:%20Co-Design%20and%20Evolution/index.md class=td-page-meta--edit target=_blank rel=noopener><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="https://github.com/shashankprasanna/shashankprasanna.com/new/main/content/en/blog/AI%20Accelerators%20and%20Machine%20Learning%20Algorithms:%20Co-Design%20and%20Evolution/index.md?filename=change-me.md&amp;value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" class=td-page-meta--child target=_blank rel=noopener><i class="fa fa-edit fa-fw"></i> Create child page</a>
<a href="https://github.com/shashankprasanna/shashankprasanna.com/issues/new?title=AI%20Accelerators%20and%20Machine%20Learning%20Algorithms:%20Co-Design%20and%20Evolution" class=td-page-meta--issue target=_blank rel=noopener><i class="fas fa-tasks fa-fw"></i> Create documentation issue</a>
<a href=https://github.com/shashankprasanna/shashankprasanna.com/issues/new class=td-page-meta--project-issue target=_blank rel=noopener><i class="fas fa-tasks fa-fw"></i> Create project issue</a></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role=main><font color=black size=5></font>
<a class=td-rss-button title=RSS href=https://shashankprasanna.com/blog/index.xml target=_blank rel=noopener><i class="fa-solid fa-rss" aria-hidden=true></i></a><div class=td-content><h1>AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution</h1><div class=lead>Efficient algorithms and methods in machine learning for AI accelerators ‚Äî NVIDIA GPUs, Intel Habana Gaudi and AWS Trainium and Inferentia</div><div class="td-byline mb-4">By <b>Shashank Prasanna</b> |
<time datetime=2022-09-09 class=text-muted>Friday, September 09, 2022</time></div><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/ai-accelerators/ data-taxonomy-term=ai-accelerators><span class=taxonomy-label>ai accelerators</span></a></li><li><a class=taxonomy-term href=https://shashankprasanna.com/tags/gpu/ data-taxonomy-term=gpu><span class=taxonomy-label>gpu</span></a></li></ul></div></header><p>If you told me a few years ago that data scientists would be using Docker containers in their day to day work, I wouldn‚Äôt have believed you. As a member of the broader machine learning (ML) community I always considered Docker, Kubernetes, Swarm (remember that?) exotic infrastructure tools for IT/Ops experts. Today it‚Äôs a different story, rarely a day goes by when I don‚Äôt use a Docker container for training or hosting a model.
An attribute of machine learning development that makes it different from traditional software development is that it relies on specialized hardware such as GPUs, Habana Gaudi, AWS Inferentia to accelerate training and inference. This makes it challenging to have containerized deployments that are hardware-agnostic, which is one of the key benefits of containers. In this blog post I‚Äôll discuss how Docker and container technologies have evolved to address this challenge. We‚Äôll discuss:</p><ul><li>Why Docker has become an essential tool for machine learning today and how it addresses machine learning specific challenges</li><li>How Docker accesses specialized hardware resources on heterogeneous systems that have more than one type of processor (CPU + AI accelerators).</li><li>How different AI accelerators extend Docker for hardware access with examples of 1/ NVIDIA GPUs and NVIDIA Container Toolkit and 2/ AWS Inferentia and Neuron SDK support for containers</li><li>How to scale Docker containers on Kubernetes with hardware accelerated nodes</li></ul><div class="td-card card mb-4"><div class=card-body><h5 class=card-title>Read the full blog post here:<br><br><i class='fa-brands fa-medium'></i> <a href=https://medium.com/towards-data-science/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators-e076c6eb7802>How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</a></h5><p class=card-text></p></div><div class=card-footer><img src=featured.png alt></div></div><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/ aria-label="Previous - How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators" class="btn btn-primary"><span class=mr-1>‚Üê</span>Previous</a></li><li><a href=/how-pytorch-2.0-accelerates-deep-learning-with-operator-fusion-and-cpu/gpu-code-generation/ aria-label="Next - How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation" class="btn btn-primary">Next<span class=ml-1>‚Üí</span></a></li></ul></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://twitter.com/shshnkp aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=LinkedIn aria-label=LinkedIn><a class=text-white target=_blank rel=noopener href=https://www.linkedin.com/in/shashankprasanna/ aria-label=LinkedIn><i class="fab fa-linkedin"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/shashankprasanna/ aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=YouTube aria-label=YouTube><a class=text-white target=_blank rel=noopener href=https://www.youtube.com/@shashank.prasanna aria-label=YouTube><i class="fab fa-youtube"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Medium aria-label=Medium><a class=text-white target=_blank rel=noopener href=https://medium.com/@shashankprasanna aria-label=Medium><i class="fab fa-medium"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2023 Shashank Prasanna All Rights Reserved</small></div></div></div></footer></div><script src=/js/main.min.2aff983e9d0d8ecff9ed53e14b657216e2d8d2aff059bf4a5651283020995f1b.js integrity="sha256-Kv+YPp0Njs/57VPhS2VyFuLY0q/wWb9KVlEoMCCZXxs=" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script></body></html>