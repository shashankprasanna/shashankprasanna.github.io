<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.111.3"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference | Shashank Prasanna</title><meta name=description content="Learn about CPUs, GPUs, AWS Inferentia, and Amazon Elastic Inference and how to choose the right AI accelerator for inference deployment"><meta property="og:title" content="A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference"><meta property="og:description" content="Learn about CPUs, GPUs, AWS Inferentia, and Amazon Elastic Inference and how to choose the right AI accelerator for inference deployment"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/"><meta property="og:image" content="http://localhost:1313/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/featured.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2020-10-21T00:00:00+00:00"><meta property="article:modified_time" content="2020-10-21T00:00:00+00:00"><meta property="og:site_name" content="Shashank Prasanna"><meta itemprop=name content="A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference"><meta itemprop=description content="Learn about CPUs, GPUs, AWS Inferentia, and Amazon Elastic Inference and how to choose the right AI accelerator for inference deployment"><meta itemprop=datePublished content="2020-10-21T00:00:00+00:00"><meta itemprop=dateModified content="2020-10-21T00:00:00+00:00"><meta itemprop=wordCount content="305"><meta itemprop=image content="http://localhost:1313/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/featured.png"><meta itemprop=keywords content="ai accelerators,gpu,"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/featured.png"><meta name=twitter:title content="A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference"><meta name=twitter:description content="Learn about CPUs, GPUs, AWS Inferentia, and Amazon Elastic Inference and how to choose the right AI accelerator for inference deployment"><link rel=preload href=/scss/main.min.4514b1195faba3f99fe8576142ccbf96fe98bf63789864d2ca7b75ca5ca5d037.css as=style><link href=/scss/main.min.4514b1195faba3f99fe8576142ccbf96fe98bf63789864d2ca7b75ca5ca5d037.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-20Q10LSLZ7"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-20Q10LSLZ7")}</script></head><body class="td-page td-blog"><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>Shashank Prasanna</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/><span class=active>Home</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://medium.com/@shashankprasanna target=_blank><i class='fa-brands fa-medium'></i><span>Medium Blog</span><sup><i class='ps-1 fa-solid fa-up-right-from-square fa-xs' aria-hidden=true></i></sup></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/blog/><span class=active>Personal Blog</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.0e60daf61d0fd1dc96239256dbe0c89f.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.0e60daf61d0fd1dc96239256dbe0c89f.json data-offline-search-base-href=/ data-offline-search-max-results=10></div><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-blog-li><a href=/blog/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-blog><span>Personal Blog</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-how-pytorch-20-accelerates-deep-learning-with-operator-fusion-and-cpugpu-code-generation-li><a href=/how-pytorch-2.0-accelerates-deep-learning-with-operator-fusion-and-cpu/gpu-code-generation/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-how-pytorch-20-accelerates-deep-learning-with-operator-fusion-and-cpugpu-code-generation><span>How Pytorch 2.0 accelerates deep learning with operator fusion and CPU/GPU code-generation</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution-li><a href=/ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-ai-accelerators-and-machine-learning-algorithms-co-design-and-evolution><span>AI Accelerators and Machine Learning Algorithms: Co-Design and Evolution</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators-li><a href=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators><span>How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference-li><a href=/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference/ class="align-left pl-0 active td-sidebar-link td-sidebar-link__page" id=m-a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-elastic-inference><span class=td-sidebar-nav-active-item>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-choosing-the-right-gpu-for-deep-learning-on-aws-li><a href=/choosing-the-right-gpu-for-deep-learning-on-aws/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-choosing-the-right-gpu-for-deep-learning-on-aws><span>Choosing the right GPU for deep learning on AWS</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><div class=box><img style=vertical-align:middle src=https://shashankprasanna.com/featured-background.png alt="shashank prasanna" width=200></div><a href=https://github.com/shashankprasanna/shashankprasanna.com/tree/main/content/en/blog/A%20complete%20guide%20to%20AI%20accelerators%20for%20deep%20learning%20inference%20%e2%80%94%20GPUs,%20AWS%20Inferentia%20and%20Amazon%20Elastic%20Inference/index.md class=td-page-meta--view target=_blank rel=noopener><i class="fa fa-file-alt fa-fw"></i> View page source</a>
<a href=https://github.com/shashankprasanna/shashankprasanna.com/edit/main/content/en/blog/A%20complete%20guide%20to%20AI%20accelerators%20for%20deep%20learning%20inference%20%e2%80%94%20GPUs,%20AWS%20Inferentia%20and%20Amazon%20Elastic%20Inference/index.md class=td-page-meta--edit target=_blank rel=noopener><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="https://github.com/shashankprasanna/shashankprasanna.com/new/main/content/en/blog/A%20complete%20guide%20to%20AI%20accelerators%20for%20deep%20learning%20inference%20%e2%80%94%20GPUs,%20AWS%20Inferentia%20and%20Amazon%20Elastic%20Inference/index.md?filename=change-me.md&amp;value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" class=td-page-meta--child target=_blank rel=noopener><i class="fa fa-edit fa-fw"></i> Create child page</a>
<a href="https://github.com/shashankprasanna/shashankprasanna.com/issues/new?title=A%20complete%20guide%20to%20AI%20accelerators%20for%20deep%20learning%20inference%20%e2%80%94%20GPUs,%20AWS%20Inferentia%20and%20Amazon%20Elastic%20Inference" class=td-page-meta--issue target=_blank rel=noopener><i class="fas fa-tasks fa-fw"></i> Create documentation issue</a>
<a href=https://github.com/shashankprasanna/shashankprasanna.com/issues/new class=td-page-meta--project-issue target=_blank rel=noopener><i class="fas fa-tasks fa-fw"></i> Create project issue</a></div><div class=td-toc><nav id=TableOfContents><ul><li><ul><li><a href=#lets-start-by-answering-the-question-what-is-an-ai-accelerator>Let’s start by answering the question “What is an AI accelerator?”</a></li><li><a href=#do-i-need-an-ai-accelerator-for-machine-learning-ml-inference>Do I need an AI accelerator for machine learning (ML) inference?</a></li></ul></li></ul></nav></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role=main><font color=black size=5></font>
<a class=td-rss-button title=RSS href=http://localhost:1313/blog/index.xml target=_blank rel=noopener><i class="fa-solid fa-rss" aria-hidden=true></i></a><div class=td-content><h1>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference</h1><div class=lead>Learn about CPUs, GPUs, AWS Inferentia, and Amazon Elastic Inference and how to choose the right AI accelerator for inference deployment</div><div class="td-byline mb-4">By <b>Shashank Prasanna</b> |
<time datetime=2020-10-21 class=text-muted>Wednesday, October 21, 2020</time></div><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=http://localhost:1313/tags/ai-accelerators/ data-taxonomy-term=ai-accelerators><span class=taxonomy-label>ai accelerators</span></a></li><li><a class=taxonomy-term href=http://localhost:1313/tags/gpu/ data-taxonomy-term=gpu><span class=taxonomy-label>gpu</span></a></li></ul></div></header><h3 id=lets-start-by-answering-the-question-what-is-an-ai-accelerator>Let’s start by answering the question “What is an AI accelerator?”</h3><p>An AI accelerator is a dedicated processor designed to accelerate machine learning computations. Machine learning, and particularly its subset, deep learning is primarily composed of a large number of linear algebra computations, (i.e. matrix-matrix, matrix-vector operations) and these operations can be easily parallelized. AI accelerators are specialized hardware designed to accelerate these basic machine learning computations and improve performance, reduce latency and reduce cost of deploying machine learning based applications.</p><h3 id=do-i-need-an-ai-accelerator-for-machine-learning-ml-inference>Do I need an AI accelerator for machine learning (ML) inference?</h3><p>Let’s say you have an ML model as part of your software application. The prediction step (or inference) is often the most time consuming part of your application that directly affects user experience. A model that takes several hundreds of milliseconds to generate text translations or apply filters to images or generate product recommendations, can drive users away from your “sluggish”, “slow”, “frustrating to use” app.
By speeding up inference, you can reduce the overall application latency and deliver an app experience that can be described as “smooth”, “snappy”, and “delightful to use”. And you can speed up inference by offloading ML model prediction computation to an AI accelerator.
With great market needs comes great many product alternatives, so naturally there is more than one way to accelerate your ML models in the cloud.
In this blog post, I’ll explore three popular options:</p><ol><li>GPUs: Particularly, the high-performance NVIDIA T4 and NVIDIA V100 GPUs</li><li>AWS Inferentia: A custom designed machine learning inference chip by AWS</li><li>Amazon Elastic Inference (EI): An accelerator that saves cost by giving you access to variable-size GPU acceleration, for models that don’t need a dedicated GPU</li></ol><div class="td-card card mb-4"><div class=card-body><h5 class=card-title>Read the full blog post here:<br><br><i class='fa-brands fa-medium'></i> <a href=https://medium.com/towards-data-science/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference</a></h5><p class=card-text></p></div><div class=card-footer><img src=featured.png alt></div></div><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/choosing-the-right-gpu-for-deep-learning-on-aws/ aria-label="Previous - Choosing the right GPU for deep learning on AWS" class="btn btn-primary"><span class=mr-1>←</span>Previous</a></li><li><a href=/how-docker-runs-machine-learning-on-nvidia-gpus-aws-inferentia-and-other-hardware-ai-accelerators/ aria-label="Next - How Docker Runs Machine Learning on NVIDIA GPUs, AWS Inferentia, and Other Hardware AI Accelerators" class="btn btn-primary">Next<span class=ml-1>→</span></a></li></ul></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://twitter.com/shshnkp aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=LinkedIn aria-label=LinkedIn><a class=text-white target=_blank rel=noopener href=https://www.linkedin.com/in/shashankprasanna/ aria-label=LinkedIn><i class="fab fa-linkedin"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/shashankprasanna/ aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=YouTube aria-label=YouTube><a class=text-white target=_blank rel=noopener href=https://www.youtube.com/@shashank.prasanna aria-label=YouTube><i class="fab fa-youtube"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Medium aria-label=Medium><a class=text-white target=_blank rel=noopener href=https://medium.com/@shashankprasanna aria-label=Medium><i class="fab fa-medium"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2023 Shashank Prasanna All Rights Reserved</small></div></div></div></footer></div><script src=/js/main.min.2aff983e9d0d8ecff9ed53e14b657216e2d8d2aff059bf4a5651283020995f1b.js integrity="sha256-Kv+YPp0Njs/57VPhS2VyFuLY0q/wWb9KVlEoMCCZXxs=" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script></body></html>